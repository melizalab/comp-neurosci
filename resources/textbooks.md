---
title: 'Computational Neuroscience'
subtitle: 'Textbooks and other Resources'
documentclass: scrartcl
linkcolor: blue
header-includes:
    - \usepackage[letterpaper, margin=1in]{geometry}
    - \usepackage{mathpazo}
    - \usepackage{eulervm}
---

The majority of these resources are available through the UVA library either in physical form or as electronic texts. 

# Computational Neuroscience

- Dayan, P and Abbott, LF (2001) Theoretical Neuroscience. MIT Press
- Sterratt D, Graham B, Gillies A, and Willshaw D (2011). Principles of
  Computational Modelling in Neuroscience. Cambridge University Press.
- Eugene Izhikevich, Dynamical Systems in Neuroscience. MIT Press.

# Linear Algebra

- Strang (2020). Linear Algebra for Everyone. Wellesley-Cambridge Press (accessible text with an emphasis on concrete examples and applications in data science)
- Hiranabe (2023). [The Art of Linear Algebra](https://github.com/kenjihiranabe/The-Art-of-Linear-Algebra). (useful graphical summary of linear algebra operations)

# Statistics and Probability Theory

- Easton and McColl (1997). [Statistics Glossary](http://www.stats.gla.ac.uk/steps/glossary/).
- Stirzaker (2012). [Probability and Random Variables: A beginner's guide](https://dx.doi.org/10.1017/CBO9780511813627) (light on math, introductory, but quite detailed)
- Proschan and Shaw (2016). [Essentials of Probability Theory for Statisticians](https://dx.doi.org/10.1201/9781315370576) (more rigorous, graduate level)
- Gelman et al (2013). [Bayesian Data Analysis, 3rd edition](http://www.stat.columbia.edu/~gelman/book/)
- Hastie et al (2017). The Elements of Statistical Learning. (classic text on machine learning through the lens of statistics)
- James et al (2023). An Introduction to Statistical Learning with Applications in Python. (lighter on theory and more practically focused than Hastie et al)

